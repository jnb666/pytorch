half = true

[train_data]
dataset = "CIFAR10"
train = true
batch_size = 128
normalize = [[0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]]

[test_data]
dataset = "CIFAR10"
batch_size = 500
normalize = [[0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]]

[model]
block = [
  ["Conv2d", "$nout", {kernel_size=3, stride="$stride", padding=1, bias=false}],
  ["BatchNorm2d"],
  ["ReLU"],
  ["Conv2d", "$nout", {kernel_size=3, stride=1, padding=1, bias=false}],
  ["BatchNorm2d"],
]

shortcut = [
  ["Conv2d", "$nout", {kernel_size=1, stride="$stride", bias=false}],
  ["BatchNorm2d"],  
]

stack = [
  ["AddBlock", "block", "shortcut", {nout="$nout", stride=2}],
  ["ReLU"],
  ["block", {nout="$nout", stride=1}],
  ["ReLU"],
]

layers = [
  ["Conv2d", 64, {kernel_size=3, stride=1, padding=1, bias=false}],
  ["BatchNorm2d"],
  ["ReLU"],
  ["block", {nout=64, stride=1}],
  ["ReLU"],
  ["block", {nout=64, stride=1}],
  ["ReLU"],
  ["stack", {nout=128}],
  ["stack", {nout=256}],
  ["stack", {nout=512}],
  ["AvgPool2d", 4],
  ["Flatten"],
  ["Linear", 10 ],
]

[transform]
transforms = [
  ["RandomHorizontalFlip"],
  ["RandomCrop", { size=[32,32], padding=4, padding_mode="reflect", resample="NEAREST" }]
]

[train]
optimizer = ["SGD", {lr=0.01, momentum=0.9, nesterov=true, weight_decay=5e-4} ]
scheduler = ["CosineAnnealingLR", {T_max=100} ]
epochs = 100
shuffle = true

