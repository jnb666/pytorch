version = 2
half = true

[train_data]
dataset = "CIFAR10"
train = true
batch_size = 128
shuffle = true
transform = [
  ["RandomHorizontalFlip"],
  ["RandomCrop", { size=[32,32], padding=4, padding_mode="reflect", resample="NEAREST" }],
  ["Normalize", [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]]
]

[test_data]
dataset = "CIFAR10"
batch_size = 500
transform = [
  ["Normalize", [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]]
]

[model]
conv = [
  ["Conv2d", "$nfeat", {kernel_size=3, padding=1} ],
  ["BatchNorm2d"],
  ["ReLU", {inplace=true} ],
]

stack2 = [
  ["conv", {nfeat="$nfeat"} ],
  ["conv", {nfeat="$nfeat"} ],
  ["MaxPool2d", {kernel_size=2, stride=2}],  
]

stack3 = [
  ["conv", {nfeat="$nfeat"} ],
  ["conv", {nfeat="$nfeat"} ],
  ["conv", {nfeat="$nfeat"} ],
  ["MaxPool2d", {kernel_size=2, stride=2}],  
]

layers = [
  ["stack2", {nfeat=64} ],
  ["stack2", {nfeat=128} ],
  ["stack3", {nfeat=256} ],
  ["stack3", {nfeat=512} ],
  ["stack3", {nfeat=512} ],
  ["AvgPool2d", {kernel_size=1, stride=1}],
  ["Flatten"],
  ["Linear", 10 ],
]

[train]
optimizer = ["SGD", {lr=0.01, momentum=0.9, nesterov=true, weight_decay=5e-4} ]
scheduler = ["CosineAnnealingLR", {T_max=100} ]
epochs = 100


